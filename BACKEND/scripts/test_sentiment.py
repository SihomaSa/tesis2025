"""
SCRIPT DE PRUEBAS - UNMSM SENTIMENT ANALYSIS
Valida las mejoras del diccionario con casos reales
"""

import sys
import os
from pathlib import Path

# Agregar el directorio raÃ­z al path
BASE_DIR = Path(__file__).resolve().parent
sys.path.insert(0, str(BASE_DIR))

from app.services.sentiment_analyzer import SentimentAnalyzer
from app.utils.config import settings
import pandas as pd
from typing import List, Dict
from colorama import init, Fore, Style

# Inicializar colorama para colores en consola
init(autoreset=True)

class SentimentTester:
    """Clase para realizar pruebas del sistema de anÃ¡lisis"""
    
    def __init__(self):
        self.analyzer = SentimentAnalyzer()
        self.test_cases = self._load_test_cases()
        
    def _load_test_cases(self) -> List[Dict]:
        """Carga casos de prueba categorizados"""
        return [
            # ===== CASOS NEUTRALES (DeberÃ­an mejorar) =====
            {
                'category': 'NEUTRAL - Preguntas/Consultas',
                'cases': [
                    {'text': 'y en el ranking internacional?', 'expected': 'Neutral'},
                    {'text': 'Y en el ranking nacional?', 'expected': 'Neutral'},
                    {'text': 'Cuando es la prÃ³xima fecha?', 'expected': 'Neutral'},
                    {'text': 'Â¿A quÃ© hora se presentan?', 'expected': 'Neutral'},
                    {'text': 'Horario del open day por favor', 'expected': 'Neutral'},
                    {'text': 'InformaciÃ³n?', 'expected': 'Neutral'},
                    {'text': 'Link?', 'expected': 'Neutral'},
                    {'text': 'dÃ³nde queda el centro de salud?', 'expected': 'Neutral'},
                ]
            },
            {
                'category': 'NEUTRAL - Afirmaciones simples',
                'cases': [
                    {'text': 'Igual. Esta bien.', 'expected': 'Neutral'},
                    {'text': 'hasta donde sÃ©, ya no figura', 'expected': 'Neutral'},
                    {'text': 'Ok', 'expected': 'Neutral'},
                    {'text': 'Entendido', 'expected': 'Neutral'},
                    {'text': 'Gracias', 'expected': 'Neutral'},  # Agradecimiento simple
                    {'text': 'Ya', 'expected': 'Neutral'},
                ]
            },
            {
                'category': 'NEUTRAL - Opiniones balanceadas',
                'cases': [
                    {'text': 'Subjetivo. Un ranking oficial le darÃ­a algo de objetividad.', 'expected': 'Neutral'},
                    {'text': 'Con revisar anteriores rankings basta', 'expected': 'Neutral'},
                    {'text': 'SerÃ­a bacÃ¡n que la Sunedu lo formalice.', 'expected': 'Positivo'},  # Esto sÃ­ es positivo
                ]
            },
            
            # ===== CASOS POSITIVOS (Deben mantenerse/mejorar) =====
            {
                'category': 'POSITIVO - Orgullo y Logros',
                'cases': [
                    {'text': 'Orgulloso de nuestra alma mater â¤ï¸', 'expected': 'Positivo'},
                    {'text': 'Felicitaciones a la Decana de AmÃ©rica! ğŸ‘', 'expected': 'Positivo'},
                    {'text': 'Excelente Decana de AmÃ©rica. ğŸ‘ğŸ‘ğŸ‘', 'expected': 'Positivo'},
                    {'text': 'Orgullo sanmarquino ğŸ’ªğŸ’ª', 'expected': 'Positivo'},
                    {'text': 'Que orgullo, compaÃ±Ã±ero!!', 'expected': 'Positivo'},
                    {'text': 'Grande mi San Marcos ğŸ”¥', 'expected': 'Positivo'},
                    {'text': 'Felicidades muchachones', 'expected': 'Positivo'},
                    {'text': 'Bien merecido...vamos UNMSM', 'expected': 'Positivo'},
                ]
            },
            {
                'category': 'POSITIVO - AdmiraciÃ³n',
                'cases': [
                    {'text': 'La verdadera inalcanzable ğŸ”¥', 'expected': 'Positivo'},
                    {'text': 'Crack el cm ğŸ”¥', 'expected': 'Positivo'},
                    {'text': 'SÃºbanle el sueldo al de marketing', 'expected': 'Positivo'},
                    {'text': 'Ese admin con Master of Puppets, un personaje de cultura musical fina ğŸ”¥âœ¨', 'expected': 'Positivo'},
                    {'text': 'Lo mÃ¡ximo! ğŸ™Œ', 'expected': 'Positivo'},
                    {'text': 'Eres un capo', 'expected': 'Positivo'},
                ]
            },
            {
                'category': 'POSITIVO - CelebraciÃ³n',
                'cases': [
                    {'text': 'Nro 1 a pesar de JerÃ­ ğŸ™Œ', 'expected': 'Positivo'},  # Mixto pero mÃ¡s positivo
                    {'text': 'JAJAJA', 'expected': 'Neutral'},  # Risa sola es neutral (puede ser sarcasmo)
                    {'text': 'No me sorprende ğŸ”¥', 'expected': 'Positivo'},
                    {'text': 'ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥â¤ï¸â¤ï¸', 'expected': 'Positivo'},
                    {'text': 'Siempre San Marcos. ğŸ‘ğŸ»ğŸ‘ğŸ»ğŸ‘ğŸ»', 'expected': 'Positivo'},
                ]
            },
            
            # ===== CASOS NEGATIVOS (Deben mantenerse) =====
            {
                'category': 'NEGATIVO - CrÃ­ticas',
                'cases': [
                    {'text': 'Ya pero que nos devuelvan el acceso a Scopus', 'expected': 'Negativo'},
                    {'text': 'Lamentablemente viene retrocediendo hace dÃ©cadas ğŸ˜¢', 'expected': 'Negativo'},
                    {'text': 'Hemos bajado al 951-1000 y lo presumen', 'expected': 'Negativo'},
                    {'text': 'La mitad de la vida universitaria es hacer colağŸ˜‚', 'expected': 'Negativo'},  # Queja con humor
                    {'text': 'Veremos si es arroz con pollo o seco con huesito. ğŸ˜¢', 'expected': 'Negativo'},
                ]
            },
            {
                'category': 'NEGATIVO - GestiÃ³n/Problemas',
                'cases': [
                    {'text': 'Rectorado? Es deber de la oficina de bienestar', 'expected': 'Negativo'},
                    {'text': 'LÃ¡stima que ya no sea la primera universidad del PerÃº', 'expected': 'Negativo'},
                    {'text': 'No hay papel en los baÃ±os ps', 'expected': 'Negativo'},
                    {'text': 'me robaron mi mochila', 'expected': 'Negativo'},
                    {'text': 'pÃ©sima gestiÃ³n', 'expected': 'Negativo'},
                ]
            },
            
            # ===== CASOS MIXTOS/COMPLEJOS =====
            {
                'category': 'MIXTO - Contexto complejo',
                'cases': [
                    {'text': 'Siempre por sus alumnos, nunca por sus autoridades ni su gestiÃ³nğŸ‘', 'expected': 'Negativo'},  # CrÃ­tica fuerte al final
                    {'text': 'A pesar de la gestiÃ³n pÃºblica, siempre San Marquina de corazÃ³n â¤ï¸', 'expected': 'Positivo'},  # Amor predomina
                    {'text': 'Lo mejor de lo peor ğŸ˜ğŸ˜', 'expected': 'Negativo'},  # SarcÃ¡stico
                    {'text': 'Gracias Jeri ğŸ˜®â€ğŸ’¨ğŸ˜®â€ğŸ’¨', 'expected': 'Negativo'},  # SarcÃ¡stico
                ]
            },
            
            # ===== CASOS ESPECÃFICOS DE TUS COMENTARIOS =====
            {
                'category': 'CASOS REALES - ProblemÃ¡ticos anteriormente',
                'cases': [
                    {'text': 'UNMSM tiene historia y prestigio a nivel nacional/internacional', 'expected': 'Positivo'},
                    {'text': 'pero depende del alumno/egresado mantener ese level', 'expected': 'Neutral'},
                    {'text': 'Para mÃ­ siempre es un orgullo presentarme como sanmarquina.', 'expected': 'Positivo'},
                    {'text': 'Es mi querida alma Mater â¤ï¸', 'expected': 'Positivo'},
                    {'text': 'yo quierooo participar', 'expected': 'Positivo'},
                    {'text': 'Mi futura facultad', 'expected': 'Positivo'},
                ]
            },
        ]
    
    def run_tests(self, verbose: bool = True):
        """Ejecuta todas las pruebas"""
        print(f"\n{'='*80}")
        print(f"{Fore.CYAN}ğŸ§ª INICIANDO PRUEBAS DEL SISTEMA DE ANÃLISIS DE SENTIMIENTOS{Style.RESET_ALL}")
        print(f"{'='*80}\n")
        
        # Primero cargar o entrenar el modelo
        try:
            print(f"{Fore.YELLOW}ğŸ“¦ Cargando modelo...{Style.RESET_ALL}")
            self.analyzer.load_model()
            print(f"{Fore.GREEN}âœ… Modelo cargado exitosamente{Style.RESET_ALL}\n")
        except FileNotFoundError:
            print(f"{Fore.YELLOW}âš ï¸  Modelo no encontrado. Entrenando nuevo modelo...{Style.RESET_ALL}")
            dataset_path = settings.DATA_DIR / settings.DATASET_FILE
            
            if not dataset_path.exists():
                print(f"{Fore.RED}âŒ ERROR: Dataset no encontrado en {dataset_path}{Style.RESET_ALL}")
                print(f"{Fore.YELLOW}ğŸ’¡ Por favor, coloca el dataset en: {dataset_path}{Style.RESET_ALL}")
                return
            
            self.analyzer.load_dataset(str(dataset_path))
            self.analyzer.train_model()
            self.analyzer.save_model()
            print(f"{Fore.GREEN}âœ… Modelo entrenado y guardado{Style.RESET_ALL}\n")
        
        # Ejecutar pruebas por categorÃ­a
        total_tests = 0
        total_correct = 0
        results_by_category = {}
        
        for category_group in self.test_cases:
            category = category_group['category']
            cases = category_group['cases']
            
            print(f"\n{Fore.CYAN}{'â”€'*80}")
            print(f"ğŸ“‚ {category}")
            print(f"{'â”€'*80}{Style.RESET_ALL}\n")
            
            correct = 0
            total = len(cases)
            details = []
            
            for case in cases:
                text = case['text']
                expected = case['expected']
                
                # Analizar
                result = self.analyzer.analyze_single(text)
                predicted = result['sentiment']
                confidence = result['confidence']
                probabilities = result['probabilities']
                
                is_correct = predicted == expected
                
                if is_correct:
                    correct += 1
                    total_correct += 1
                
                total_tests += 1
                
                # Guardar detalles
                details.append({
                    'text': text,
                    'expected': expected,
                    'predicted': predicted,
                    'correct': is_correct,
                    'confidence': confidence,
                    'probabilities': probabilities
                })
                
                # Mostrar resultado
                if verbose or not is_correct:
                    status_icon = "âœ…" if is_correct else "âŒ"
                    status_color = Fore.GREEN if is_correct else Fore.RED
                    
                    print(f"{status_color}{status_icon} Texto: {text[:60]}...{Style.RESET_ALL}")
                    print(f"   Esperado: {Fore.YELLOW}{expected}{Style.RESET_ALL} | "
                          f"Obtenido: {status_color}{predicted}{Style.RESET_ALL} "
                          f"({confidence:.2%})")
                    
                    if not is_correct:
                        print(f"   ğŸ“Š Probabilidades: "
                              f"Neg={probabilities['negativo']:.3f}, "
                              f"Neu={probabilities['neutral']:.3f}, "
                              f"Pos={probabilities['positivo']:.3f}")
                    print()
            
            # Resumen de categorÃ­a
            accuracy = correct / total if total > 0 else 0
            results_by_category[category] = {
                'correct': correct,
                'total': total,
                'accuracy': accuracy,
                'details': details
            }
            
            acc_color = Fore.GREEN if accuracy >= 0.8 else Fore.YELLOW if accuracy >= 0.6 else Fore.RED
            print(f"{acc_color}ğŸ“Š PrecisiÃ³n en {category}: {correct}/{total} ({accuracy:.1%}){Style.RESET_ALL}\n")
        
        # Resumen general
        self._print_summary(total_correct, total_tests, results_by_category)
        
        return results_by_category
    
    def _print_summary(self, total_correct: int, total_tests: int, results: Dict):
        """Imprime resumen general de resultados"""
        overall_accuracy = total_correct / total_tests if total_tests > 0 else 0
        
        print(f"\n{'='*80}")
        print(f"{Fore.CYAN}ğŸ“Š RESUMEN GENERAL{Style.RESET_ALL}")
        print(f"{'='*80}\n")
        
        print(f"Total de pruebas: {total_tests}")
        print(f"Correctas: {Fore.GREEN}{total_correct}{Style.RESET_ALL}")
        print(f"Incorrectas: {Fore.RED}{total_tests - total_correct}{Style.RESET_ALL}")
        
        acc_color = Fore.GREEN if overall_accuracy >= 0.8 else Fore.YELLOW if overall_accuracy >= 0.6 else Fore.RED
        print(f"\n{acc_color}ğŸ¯ PRECISIÃ“N TOTAL: {overall_accuracy:.1%}{Style.RESET_ALL}\n")
        
        # Desglose por sentimiento esperado
        print(f"{Fore.CYAN}ğŸ“ˆ PrecisiÃ³n por Tipo de Sentimiento:{Style.RESET_ALL}\n")
        
        sentiment_stats = {'Positivo': {'correct': 0, 'total': 0},
                          'Negativo': {'correct': 0, 'total': 0},
                          'Neutral': {'correct': 0, 'total': 0}}
        
        for category, data in results.items():
            for detail in data['details']:
                expected = detail['expected']
                if expected in sentiment_stats:
                    sentiment_stats[expected]['total'] += 1
                    if detail['correct']:
                        sentiment_stats[expected]['correct'] += 1
        
        for sentiment, stats in sentiment_stats.items():
            if stats['total'] > 0:
                acc = stats['correct'] / stats['total']
                color = Fore.GREEN if acc >= 0.8 else Fore.YELLOW if acc >= 0.6 else Fore.RED
                icon = "ğŸ˜Š" if sentiment == "Positivo" else "ğŸ˜¡" if sentiment == "Negativo" else "ğŸ˜"
                print(f"{icon} {sentiment:10} : {color}{stats['correct']:2}/{stats['total']:2} ({acc:.1%}){Style.RESET_ALL}")
        
        # Casos mÃ¡s problemÃ¡ticos
        print(f"\n{Fore.YELLOW}âš ï¸  CategorÃ­as que necesitan mejora:{Style.RESET_ALL}\n")
        
        problem_categories = [(cat, data) for cat, data in results.items() 
                             if data['accuracy'] < 0.7]
        
        if problem_categories:
            for category, data in sorted(problem_categories, key=lambda x: x[1]['accuracy']):
                print(f"   â€¢ {category}: {data['accuracy']:.1%}")
        else:
            print(f"   {Fore.GREEN}âœ¨ Â¡Todas las categorÃ­as tienen >70% de precisiÃ³n!{Style.RESET_ALL}")
        
        print(f"\n{'='*80}\n")
    
    def test_specific_cases(self, cases: List[str]):
        """Prueba casos especÃ­ficos ingresados manualmente"""
        print(f"\n{Fore.CYAN}ğŸ” PRUEBA DE CASOS ESPECÃFICOS{Style.RESET_ALL}\n")
        
        for i, text in enumerate(cases, 1):
            result = self.analyzer.analyze_single(text)
            
            sentiment = result['sentiment']
            confidence = result['confidence']
            probabilities = result['probabilities']
            
            color = (Fore.GREEN if sentiment == "Positivo" else 
                    Fore.RED if sentiment == "Negativo" else 
                    Fore.YELLOW)
            
            print(f"{i}. {Fore.WHITE}'{text}'{Style.RESET_ALL}")
            print(f"   Sentimiento: {color}{sentiment}{Style.RESET_ALL} ({confidence:.2%})")
            print(f"   Probabilidades: Neg={probabilities['negativo']:.3f}, "
                  f"Neu={probabilities['neutral']:.3f}, Pos={probabilities['positivo']:.3f}")
            print()


def main():
    """FunciÃ³n principal"""
    print(f"\n{Fore.MAGENTA}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print(f"â•‘  SISTEMA DE PRUEBAS - UNMSM SENTIMENT ANALYSIS v3.1          â•‘")
    print(f"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{Style.RESET_ALL}\n")
    
    tester = SentimentTester()
    
    # Ejecutar suite completa de pruebas
    results = tester.run_tests(verbose=False)  # verbose=False para solo mostrar errores
    
    # Pruebas adicionales personalizadas (opcional)
    print(f"\n{Fore.CYAN}ğŸ’¡ Â¿Deseas probar casos adicionales? (s/n): {Style.RESET_ALL}", end='')
    
    # Para testing automÃ¡tico, comentar lo siguiente
    # response = input().strip().lower()
    # if response == 's':
    #     print("Ingresa los textos (Enter dos veces para terminar):\n")
    #     custom_cases = []
    #     while True:
    #         text = input("â¤ ")
    #         if text.strip() == "":
    #             break
    #         custom_cases.append(text)
        
    #     if custom_cases:
    #         tester.test_specific_cases(custom_cases)
    
    print(f"\n{Fore.GREEN}âœ¨ Pruebas completadas{Style.RESET_ALL}\n")


if __name__ == "__main__":
    main()